\section{Alternative Fault Tolerance Methods}
\label{sec:fault_tolerance_approaches}

We now examine a number of alternative fault tolerance schemes and
their applicability to ``dense'' clusters.

\subsection{Replication}

Systems that employ replication for fault tolerance store multiple copies, or
replicas, of intermediate data in the system simultaneously. The granularity of
this replication can vary: whole files, the blocks that comprise a file, or
even individual records may be replicated. To prevent correlated failures from
causing data loss, these replicas are often stored in different failure
domains; for example, replicas might be stored on different hosts, different
racks, or even geographically-separated data centers. If one of the replicas is
lost, another replica can be used in its place, either by migrating it or
accessing it remotely.

While MapReduce typically relies on some degree of replication in its input and
output data for fault tolerance, intermediate data generated by individual \map
tasks is typically not replicated due to the high overhead both in terms of
storage space and bandwidth involved (though Ko et al. explore mitigating these
effects in ~\cite{ko-intermediate}).

\subsection{Upstream backup}

The task-level fault tolerance scheme currently used in MapReduce is an example
of a class of fault tolerance called \textit{upstream
  backup}~\cite{magda-ft,spark}.  In upstream backup, the output of an operator
is buffered locally on disk before being sent over the network to subsequent
operators.  If the downstream operator fails (due to node failure, for
example), its inputs can be sent to a replacement instance of the operator
without having to re-run the map tasks that generated those inputs.  Upstream
backup is a restricted form of keeping a bounded history in dataflow
systems~\cite{magda-ft}.

\subsection{Parallel Recovery}

A disadvantage of upstream backup is that the
recovery latency can be high because recovery of a downstream operator is
limited to the speed at which the slowest upstream node can send data to it.
In parallel recovery, intermediate data is additionally checkpointed on many
separate nodes.  When a failure occurs, each of these nodes can contribute a
small portion of the recovery data to the new downstream operator.  This
enables significant parallelism, reducing the time required to recover the
data. Spark's D-Streams~\cite{dstreams} and RAMCloud~\cite{ramcloud-ft} both
employ parallel recovery.

\subsection{Process-Pairs}

In systems employing process-pairs
parallelism~\cite{gray-reuter}, two replicas of the same computation are
executed simultaneously. In the traditional definition, checkpoints of the
primary's execution are periodically sent to the backup and, if the primary
fails, the backup assumes the primary's role and a new backup is
instantiated. FLuX~\cite{flux} applies the process-pairs approach to the
continuous query domain, providing process pairs on either side of a network
transmission and providing seamless fail-over. While this approach allows the
computation to continue in the face of a limited amount of failure, it
potentially imposes significant additional network bandwidth and compute
overhead.

\subsection{Provenance and Selective Replay}

The above mechanisms work to
ensure that data itself is kept fault-tolerant. Fault tolerance mechanisms
based on provenance and replay ensure instead that the sequence of steps
necessary to reproduce each piece of intermediate data are kept fault tolerant,
while the intermediate data itself is volatile. MapReduce employs a limited
form of provenance; a map task's output can be recomputed if the function that
task was running and the data over which it was running are known, without
recomputing anything else.

The storage requirements of maintaining provenance information depend largely
on its granularity. For example, the overhead of record-level provenance is a
function of the number of intermediate records, which can be quite large at
scale.  However, provenance can be quite effective when kept at a much
coarser-grained level.  Spark maintains provenance at the Resilient Distributed
Dataset (RDD) level, which requires much less overhead than record-level
bookkeeping. However, the Spark authors point out that they perform upstream
backup of intermediate records for what they call ``wide dependencies'', of
which MapReduce's all-to-all shuffle is one, ``... to simplify fault
recovery''~\cite{spark}.

\subsection{Scan-Sharing}

Scan-sharing~\cite{qptmd} is a form of multi-query optimization
in which the output of a scan of a dataset is used by more than one job at a
time. This optimization takes advantage of the fact that some datasets are much
more popular than others. Jobs that share the same data can be co-scheduled and
``share'' scans of that data, effectively eliminating the I/O overhead for all
but one of the jobs.  For I/O-bound workloads, this provides a significant
reduction in overhead, and does not require any additional storage overhead or
maintenance of provenance.
